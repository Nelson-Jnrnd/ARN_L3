{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Loading the packages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "from ipywidgets import interact, widgets\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "PATH = '../vowels'\n",
    "\n",
    "from python_speech_features import mfcc\n",
    "import scipy.io.wavfile as wav\n",
    "\n",
    "import glob\n",
    "nam_paths = glob.glob(os.path.join(PATH, 'nam*.wav'))\n",
    "naf_paths = glob.glob(os.path.join(PATH, 'naf*.wav'))\n",
    "nk_paths = glob.glob(os.path.join(PATH, 'nk*.wav'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Imports Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Here we read the wave files and store their content in lists\n",
    "naf_audios = [wav.read(path) for path in naf_paths]\n",
    "nam_audios = [wav.read(path) for path in nam_paths]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nam_audios"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Analyse DATA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1080x288 with 2 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA28AAAEICAYAAADIocw3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAlJElEQVR4nO3df5wkd13n8deHXQTJQjJLYIUkZ9YTvGH3gLBrRF11m0X5IUdEOS8jKuBKvHvAgnf8jHMHyd2N4nEngt6pdwy/DnaCoEgODBCSHjWHQTcQYMOABg0ELhBgF8KCBnf93B/Ts/QOM90z3V1VXV2v5+NRj+2u7q53dW1PfftT9a1vR2YiSZIkSRpv96h6BSRJkiRJ/Vm8SZIkSVINWLxJkiRJUg1YvEmSJElSDVi8SZIkSVINWLxJkiRJUg1YvEkli4jXR8R/rno91jPu6ydJaqYy2ifbQI07izdNlIi4LSLujIizuub9YkQsbvD1V0TEmwpbwf75z4iIUxFxomv67arWR5LUDBPSfmZEvHLV/Es6819f0apJI2Xxpkm0BXheFcERsXUEi/nzzNzWNT1nBMuUJKmfurefnwR+etWyng781QiWLY0FizdNolcAL4iIc9Z6MCJeFRG3R8RdEXFTRPxQZ/7jgV8B/lXnjNeHO/Nvi4jHdr3+9NHFiLiwc0TvYER8Gri+M/+tEfG5iPhKRPxpROwa9k1FxJMi4uaI+HJEvD8iHt712G0R8cKI+EhEfC0i5iNiR0RcExFfjYj3RcRU1/M3vH69ciVJE6Xu7efngI8Cj+ssazvwA8DVq96HbaBqy+JNk+gIsAi8YJ3H/xJ4JLAdOAy8NSLunZnvBn4VeEvnjNcjNpH5I8A0nQYDuAZ4CPBA4IPAmzf5Hs4QERcBrwV+Cbg/8HvA1RFxr66n/RTwo8BDgX/RWYdfAR7A8t/6c7ueu6H122CuJGkyTEL7+Ubg5zu3LwXeAdy96jm2gaotizdNqpcChyLiAasfyMw3ZeaXMvNkZv434F7A9wyZd0Vmfi0z/66T8drM/Gpm3g1cATwiIs7e4LIe3TnCtzI9GrgM+L3M/EBmnsrMN7DcGD2663W/lZmfz8zPAn8GfCAzP5SZfw+8HbioaxtsdP02kitJmhx1bj9hub3b33nNz7NczK1+H7aBqi2LN02kzDwKvBN4yerHIuIFEbHU6S7xZeBs4NwhI2/vWv6WiHh5RHwyIu4Cbus8tNGMGzPznK7pRuA7ged3F3XABcCDu173+a7bf7fG/W0DrN9GciVJE6Lm7SedIvBdwL8H7p+Z/3fVe7ANVK1ZvGmSvQx4FnDeyoxO//wXAT8NTGXmOcBXgOg8JddYzteA+3Td/441ntP9up8BLgEey3LDduFK/GbfQJfbgblVRd19MnNhgGVtZv1GmStJqoe6t59vBJ4PrDX6pW2gas3iTRMrM28F3sKZ13rdFzgJfAHYGhEvBe7X9fjngQsjovtv42bg0oi4Z0TsBZ7aJ/q+LHer+BLLjdavDvM+Ov4X8K8j4vti2VkR8eMRcd8BlrWZ9RtlriSpBiag/fwTlq8B/60hM2wDNXYs3jTp/iNwVtf99wDvZnnY4E8Bf09Xlw3grZ1/vxQRH+zc/g/APwWOA1eyfJF2L2/sLPuzwMeAG4dYfwAy8wjLR0F/u7MetwLPGHBxG16/EedKkuqjtu1nLrsuM48Nk2EbqHEUmWud5ZYkSZIkjRPPvEmSJElSDVi8SZIkSVINWLxJkiRJUg1YvEmSJElSDWytegW6nXvuuXnhhRcO9Nqvfe1rnHXWWf2fOEJNyawq18zJyzVz8nKHybzpppu+mJkPGPEqTaxB20g/j2bWObcpmVXlmjmeuT3bx8wcm2nPnj05qHa7PfBrzRzPXDMnL9fMycsdJhM4kmPQ9tRlGrSN9PNoZp1zm5JZVa6Z45nbq32026QkSZIk1YDFmyRJkiTVgMWbJEmSJNWAxZskSZIk1YDFmyRJkiTVgMWbJEmSJNWAxZt6WlhYYPfu3Rw4cIDdu3ezsLBQ9SpJkiRJjTSyH+mOiC3AEeCzmfmkiNgJXAXcH7gJ+LnM/Mao8lS8hYUFZmdnmZ+f59SpU2zZsoWDBw8CMDMzU/HaSZIkSc0yyjNvzwOWuu7/OvDKzPxu4DhwcIRZKsHc3Bzz8/O0Wi22bt1Kq9Vifn6eubm5qldNkqTKRMTpqdVqnXE/IqpePUkTbCTFW0ScD/w48JrO/QAeA7yt85Q3AD8xiiyVZ2lpiX379p0xb9++fSwtLa3zCkmSJl9mnp5W31+ZJ0lFiFHsZCLibcCvAfcFXgA8A7ixc9aNiLgAuCYzd6/x2suAywB27Nix56qrrhpoHU6cOMG2bdsGeu2gJj3zmc98Js997nO56KKLTud+6EMf4tWvfjWve93rCs+f9O1bZWZVuWZOXu4wma1W66bM3DviVZooo2gj/TwWq9Vq0W63S830/3TyMqvKNXM8c3u2j6uPFm12Ap4E/I/O7f3AO4FzgVu7nnMBcLTfsvbs2ZODarfbA7/WzLUdPnw4d+7cmddff31ee+21ef311+fOnTvz8OHDpeRP+vatMrOqXDMnL3eYTOBIDtkGNWkatI3081is5a9S5fL/dPIyq8o1czxze7WPoxiw5AeBJ0fEE4F7A/cDXgWcExFbM/MkcD7w2RFkqUQrg5IcOnSIpaUlpqenmZubc7ASSZIkqQJDF2+ZeTlwOUBE7AdekJlPi4i3Ak9lecTJpwPvGDZL5ZuZmWFmZobFxUX2799f9epIktRI/QZCSa+1kxqhyN95ezHw7yLiVpZ/LmC+wCxJkqSJ1d1tavV9CzepOUb2O28AmbkILHZu/w1w8SiXL0mSJI2aZzZVFyMt3iRJkqS66S7OIsJiTWOryG6TkiRJkqQRsXiTJEmSpBFZWFhg9+7dHDhwgN27d7OwsDCyZdttUpIkSWoAr+0r3sLCArOzs8zPz3Pq1Cm2bNnCwYMHAUbyc1ueeZMkSZIaYK1RSh21dLTm5uaYn5+n1WqxdetWWq0W8/PzzM3NjWT5nnmTJEnSWOh3Zgg8O6TxtrS0xL59+86Yt2/fPpaWlkayfM+8SZIkaSz0OzNk4aZxNz09zQ033HDGvBtuuIHp6emRLN/iTZIkSZJGYHZ2loMHD9Jutzl58iTtdpuDBw8yOzs7kuXbbVJjZ2Fhgbm5OZaWlpienmZ2dnYkF3hKkiRJRVr5znro0KHT32Xn5uZG9l3W4k1jpegReiRJkqQizczMMDMzw+LiIvv37x/psu02qTVFxBlTq9U6435Rih6hR5IkSaorz7xpTasvCI6IUi4SLnqEHkmSJKkIZfyOnmfeNFaKHqFHKtLCwgK7d+/mwIED7N69m4WFhapXSZIklaSM39HzzJvGysoIPSvXvK2M0DNp3SbLODKjcnm9piRJKprFm8ZK0SP0jIvu4qysLqkqVvf1misXKM/Pz3Po0KGJ+/xKkqRqWLxp7BQ5Qo9UFK/XlCRJRfOaN0kaAa/XlCRJRbN4k6QRWLles91uc/LkydPXa87Ozla9apIkaULYbVKSRqAp12tKkqTqeOZtAA4HLmktMzMzHD16lOuuu46jR49auEmSpJHyzNsmORy4JEmSpCpYvG2Sw4EXp99vn4G/fyZJklQnfr8bLYu3TXI48OKs/sP19880KH8EXZKk8eD3u9HymrdNcjhwafxl5ulp9X0bDEmSVFcWb5vkcOCS5MBNkiRVwW6Tm+Rw4JKazoGbJKketm/fzvHjx3s+Z71LDaampjh27FgRq6UhDH3mLSIuiIh2RHwsIm6JiOd15m+PiGsj4q87/04Nv7pn5J4xtVqtM+4XyeHAJTVZ98BNW7dupdVqMT8/z9zcXNWrpo5e7WPRbaSk8XH8+PFvuXSge2q32+s+1q/oUzVGcebtJPD8zPxgRNwXuCkirgWeAVyXmS+PiJcALwFePFTSFWefvpkvu9+Gn7t8/ytDRUuSljlw0/jZyNH1bt0FnEfXJak+hi7eMvMO4I7O7a9GxBJwHnAJsL/ztDcAiwxZvMWVdw30uqmpKY5dMUyyJGnFysBNrVbr9DwHbqrWseeeAvoc1FzXqVGuiiSpQCO95i0iLgQuAj4A7OgUdgCfA3as85rLgMsAduzYweLi4rrLb7fbp293f2no91yg53IHdeLEiUKWO26ZK6rIbcr2rSKzSZ/fprzPsnKf8pSn8LSnPY0XvvCF7Ny5k1e+8pW84hWv4ODBg5XtnybVhtvI/e844+5m20hsI4fSlEy3b7GK2r69ltkvs6jt0JR9AxTwXnv1g93MBGwDbgJ+snP/y6seP95vGXv27MnN2LVrV15//fWZmdlutzMz8/rrr89du3ZtajmDWsksw+HDh3PXrl15j3vcI3ft2pWHDx8uLTszc/mjUq4qMsv8P11RxfvMrOa9NmX7VvE+y84dxT4JOJIjaoOaMG2mjayifQR6TmWYpH3M1NRU32263jQ1NVXIOk3S9h23zMxitm+/99Irs6jt0KR2edD32qt9HMmZt4i4J/AHwJsz8w87sz8fEQ/KzDsi4kHAnaPI6rYybP/KiGcrw/ZP2kXzjuwmadzMzMwwMzPD4uIi+/fvr3p1tEoV1yUuf9/4Jn+IdzgrA02spd/fnYPSSJNrFKNNBjAPLGXmb3Q9dDXw9M7tpwPvWP3aYc3MzDA3N8ehQ4d43OMex6FDhyZy2H5HdpMkbcbKdYndvC5RkupvFGfefhD4OeCjEXFzZ96vAC8Hfj8iDgKfAn56BFnfoglHfx3ZTaPQ70isR8ilydGUnikbOcPkvk3SJBnFaJM3AOvtPQ8Mu3w5sptGwy5NUnOs9EA5dOgQS0tLTE9PT2TPFPdrkppmpKNNTrqqjvA15QiqVGee2dS4aULPFElqGou3TajqCF9TjqBq8jSpS1P3+/DovyRJKoLFW014BFV1ZJcmSZKk0Rl6tElJkiRJUvE88yZJ2rAmdYWVpCJ5rbQGYfEmSdowu8JK0mi4Py3WpBbHFm+SJEmSJsqkDiTmNW+SJEmSVAMWb5IkSWqU7du3ExFrTsC6j0UE27dvr3jtx9+g29dt25/dJmtgUvvsShqO+wZJGszx48fX3Uf2+1mmjQzc1HSDbt+6bdvt27dz/Pjxns9Z7z1NTU1x7NixTWd65q0GMvP0tPq+X86k5lprX+C+QZKkcqwUqetN7XZ73cf6FX3rsXiTJEmSpBqw26Qaz65nkiRpEuXL7gdXnL3u4/sBFnu8VmPH4q2Pfn1ZR92PVeWb1KFkJUlSs8WVd/X8XtPv+rO8opj10uAs3vpoygWXkiRtRhUX6jdJrzMm+2HdsyWnXytpIlm8SZKkTet1cBMm6wBnFb1wep0x2choiJ4xkSaTA5ZIkiT10GtEuSJGk5Ok9Vi8SZIkSVINWLypUtu3byci1pyAdR/bvn17xWsuSZKkcTHod8q6fa+0eFOl7IoiSZKkYQ36nbJu3ysdsKSPQUd7cqQnSZIkSaNk8dbHoKM9OdKTVJ5BR4IDhyyXJEn1YbdJAb37CXv9mcZdU7pKSJKkZrN4E9D7y6/Xn0mSJEnVs9ukJA2gSV01q/iBYo2/XteEg9eFa+Pcx0gbV3jxFhGPB14FbAFek5kvLzpTkoq2crZ6Lb2uh4Xehd04GvS91u19anN6XRMOXheujXMfo7qq4iBWocVbRGwB/jvwo8BngL+MiKsz82NF5o7aIDuHqampAtZEGn8eQZUkSU1QxUGsos+8XQzcmpl/AxARVwGXALUp3nr9h0REz8cH1aTuWJo8HkGVNGma+rNB/fbLRXwH0mRo6t9MGYou3s4Dbu+6/xng+7qfEBGXAZcB7Nixg8XFxYGCTpw4MfBrh1FE5vHjx2m322s+duLECbZt27bua1ut1sDr1Ot1/bbvoJnD/HEX9f89KZ+jKnPXW25Rn6NhMofJrSKzn0n6P9Vo2sgi28cq2o1+ilhu68q7BmqXW60W7f2Dr0/V+5jV77nVap0xb5TbuintRj9FLLeKv9Mm/c2UvX2jyKMmEfFU4PGZ+Yud+z8HfF9mPmet5+/duzePHDkyUFa/a0yKUNSZt17L3ci1NIOsU7/X9T3tO+B2GPS9VrHth9HvbGovRZ1NHbfPbxWfo2Fyq8gcZp2KWu4w/6cRcVNm7h3FOjbBoG1kUe1jVe3GMOtUxHInab82zDoVtVy3b7HLHLftO9Q26HHt2cZe/5VNv6So7durfSz6zNtngQu67p/fmSc1SpMGt5AkSSpbr+vPNlSQX1HMeo1a0cXbXwIPiYidLBdtlwI/U3CmJEmStK5BL9s4/VqpIoUWb5l5MiKeA7yH5Z8KeG1m3lJkpqTmaUojvJHut47mKU2OQXteOOJ1f005S6PJU/jvvGXmHwN/XHROGdbaia6e58hLUvma0gj36n4LxY3m6ahhWk8VxUVTfo6kitGuJY2/wou3SbJ6R1nFICmSVLZBi+M6FcbavH7FQ1EFhj9HIqnJLN4kSZKkCWX322KVvX0t3sZQU67fUbG8PkqSpGar6gx5U1SxfS3exlBTrt9Rsaq6PkqSJEnFsHiTpJrodVYeHDxEkqRJZ/EmSTXR66w8OHiIJEmTzuJNkiRJUu01YXAWizcBdseSNsuBhSRJGh9N+W1EizcBdseSNsuBhSRJUtks3iSN1KBnpDwbJWkj3MdIajKLN0kjNegZKc9GjbdBriOo0zUEqg/3MZKazOJNlfNLoTTemnIdgSRJ487ibUw1YbQc8EuhJEmStFEWb2PIgkaj4AiikiSNj+3bt3P8+PGez1nv4P3U1BTHjh0rYrVUMxZv0oRyBNHiVXGGvCln5SVp0hw/fnyodrluvCymGBZvkjSAKs6Q91umZ+YlSePAXmTFsXiTJElSZfz5B2njLN7UOP36nNvfvJ7sTihJ9eTPP0gbZ/GmxunV57yo/uaDHlU8/Vr1ZPcMqXpr7SO75/l3KEnDs3iTSjDoUUXwyKKkeli9j+u3b5Mkbd49ql4BSZIkSVJ/nnnTaV4zJElSc/k7ZNJwyug+7pk3Acsfpl5Tr+e4s5Ykqf5Wrglfb2q32+s+1q/ok5qg39/MKHjmTZIk1Yo//qtRsMeR6sjiTZIk1Yajy2oU/ByprobqNhkRr4iIj0fERyLi7RFxTtdjl0fErRHxiYh43NBrKkmSJEkNNuyZt2uByzPzZET8OnA58OKIeBhwKbALeDDwvoh4aGaeGjJPUg3YpUnSpHG/JmkcDFW8ZeZ7u+7eCDy1c/sS4KrMvBv424i4FbgY+PNh8iSNP7uiSJo07teKZ3Esbcwor3n7BeAtndvnsVzMrfhMZ54GsHqHtvq+jYYkSaori2Np4/oWbxHxPuA71nhoNjPf0XnOLHASePNmVyAiLgMuA9ixYweLi4ubXQQAJ06cGPi1gyors91un5G5bdu2Mx4v632XvX2LzFxvuf3+T4dZn0Ezh8nt9boi32svk/Q5GrfMqnKreq9NMIo2sor2scpcM4tbru3GcPJl94Mrzl738f0A68Tmy+7n9q1hZhH7wRj2aEZEPAP4JeBAZn69M+9ygMz8tc799wBXZGbPbpN79+7NI0eODLQei4uL7N+/f6DXDqopmVDNka/CMnvsOPu/9isDvazXe+n3fzroduj3ul65RW37ifocjVlmVbnDZEbETZm5d8SrNLEGbSOrajeqyK3b38Bmc3oZxTrYbhSb6fZtViYMvh/s1T4O1W0yIh4PvAj4kZXCreNq4HBE/AbLA5Y8BPiLYbKkUYkr7xqokIoI8ori1qsI/oaNJE2G7narqoJc9bfW94LueXZRHX9D/VQA8NvAfYFrI+LmiPhdgMy8Bfh94GPAu4FnO9KkVK7M7Dn1es6xY8cqXntJ6i8izpjWmydp2er2vt1uf8t3A423YUeb/O4ej80Bc8MsX5IkaT2rv2x6RkrSpBvlaJOS1FhVjApr9xdJkprF4k2SRqCK61FWMhcWFpibm2NpaYnp6WlmZ2eZmZkpPF/SZBl2NERJxbN4k6QaW1hYYHZ2lvn5eU6dOsWWLVs4ePAggAWcpE3pNaAXTN6gXlIdDTtgiSSpQnNzc8zPz9Nqtdi6dSutVov5+Xnm5rzkWJLUXJM6mJFn3qSSOGy/irC0tMS+ffvOmLdv3z6WlpYqWiNJkr6p3/XZUMw12pP68xqeeZNKMOiQ/Q7br36mp6e54YYbzph3ww03MD09XdEaSZL0Tf1+nsDBtTbH4k2Samx2dpaDBw/Sbrc5efIk7XabgwcPMjs7W/WqSZKkEbPbpCTV2MzMDO9///t5whOewN1338297nUvnvWsZxU2WElV3V8kSZJn3iSp1hYWFnjXu97FNddcw7XXXss111zDu971LhYWFgrJs/uLJEnVsXiTpBpztElJkprDbpMaG3bHkjbP0SYljZIjI0vjzTNvGhtldsda/VsfK1Or1Vr3MRsmjSNHm5Q0Kr1GPu43OrIjI0vlsHhT49gwaZI42qQkSc1ht0lJqrGVUSUPHTrE0tIS09PTzM3NFTbapCRJqo7FmyTV3MzMDDMzMywuLrJ///6qV0eSBub171JvdpuUJEnSWPDnSKTeLN4kSZIkqQYs3iRJkiSpBizeJEmSJKkGHLBEkiRJjbZ6UBQHSdG48sybpMKs/qHz9eYVmVtWpiSpvhwkRXVh8SapMFWNGmYjLEmSJpHFmyRJkiTVgMWbJEmSJNWAA5ZoTWtdF9Q9z65nw/HCaEmSJG2WZ960pn7XKmk4XpMlSVLzrB5Aq3tqtVrrPjY1NVX1qmtMjKR4i4jnR0RGxLmd+xERr46IWyPiIxHxqFHkSJIkSXW0+kDtWgdu13vs2LFjFa+9xsXQxVtEXAD8GPDprtlPAB7SmS4DfmfYHEmSJElqslGceXsl8CKgu6/XJcAbc9mNwDkR8aARZEmSJElSI8Uw19dExCXAYzLzeRFxG7A3M78YEe8EXp6ZN3Sedx3w4sw8ssYyLmP57Bw7duzYc9VVVw20LidOnGDbtm0DvpPBNCWzqtwqMlutFu12u9TMqv5Pm/Jem5JZVe4wma1W66bM3DviVZooo2gj/TwWqyn7UmjOe3X7mll1bs/2cQP9b98HHF1jugT4AHB253m3Aed2br8T2Ne1jOtYLux6Zu3ZsycH1W63B36tmeOZW0Xm8p9Euar6P23Ke21KZlW5w2QCR7JPu+A0fBvp57FYTdmXZjbnvbp9zaw6t1f72PenAjLzsWvNj4h/DuwEPtwZ5vx84IMRcTHwWeCCrqef35knSZIkSRrAwNe8ZeZHM/OBmXlhZl4IfAZ4VGZ+Drga+PnOqJOPBr6SmXeMZpUlSZIkqXmK+pHuPwaeCNwKfB14ZkE5kiRJktQIIyveOmffVm4n8OxRLVuSJEmSmq6oM2+SJEkTqXOt/7r3c4iRvCWpl1H8zpskSVJjdI/81m631xqpW5IK4Zk3NZ5HUCVJklQHnnlT43kEVZIkSXXgmTepIVafUVw9z0JVkiRpvHnmTWqI1WcUV59llCSpW0ScMa2eJ6l8Fm+SJEn6Fh70k8aPxZskSZIk1YDFmyRJkiTVgMWbJEmSJNWAxZskSZIk1YDFmyRJkiTVgMWbJEmSJNWAxZskSZIk1YDFmyRJkiTVgMWbJEmSJNWAxZskSZIk1YDFmyRJkiTVgMWbJEmSJNWAxZskSZIk1YDFmyRJkiTVgMWbJEmSJNWAxZskSZIk1YDFmyRJkiTVgMWbJEmSJNXA0MVbRByKiI9HxC0R8V+65l8eEbdGxCci4nHD5kiSJElSk20d5sUR0QIuAR6RmXdHxAM78x8GXArsAh4MvC8iHpqZp4ZdYUmSJElqomHPvP0b4OWZeTdAZt7ZmX8JcFVm3p2ZfwvcClw8ZJYkSZIkNdawxdtDgR+KiA9ExJ9ExPd25p8H3N71vM905kmSJEmSBhCZ2fsJEe8DvmONh2aBOaANPBf4XuAtwHcBvwXcmJlv6ixjHrgmM9+2xvIvAy4D2LFjx56rrrpqoDdy4sQJtm3bNtBrB9WUzKpyzZy8XDMnL3eYzFardVNm7h3xKk2UUbSRfh7NrHNuUzIBWq0W7Xa71MymbN+6/c30bB8zc+AJeDfQ6rr/SeABwOXA5V3z3wN8f7/l7dmzJwfVbrcHfq2Z45lr5uTlmjl5ucNkAkdyiDaoadOgbaSfRzPrnNuUzMzM5a/l5WrK9q3b30yv9nHYbpN/BLQAIuKhwLcBXwSuBi6NiHtFxE7gIcBfDJklSZIkSY011GiTwGuB10bEUeAbwNM71eItEfH7wMeAk8Cz05EmJUmSJGlgQxVvmfkN4GfXeWyO5WviJEmSJElDGvpHuiVJkiRJxbN4kyRJkqQasHiTJEmSpBqweJMkSZKkGrB4kyRJkqQasHiTJEmSpBqweJMkSZKkGrB4kyRJkqQasHiTJEmSpBqweJMkSZKkGrB4kyRJkqQasHiTJEmSpBqweJMkSZKkGrB4kyRJkqQasHiTJEmSpBqweJMkSZKkGrB4kyRJkqQasHiTJEmSpBrYWvUKSJIkSU0TET3nZWaZq6Oa8MybJEmSVLLMPGNqt9tn3JfWYvEmSZIkSTVg8SZJkiRJNWDxJkmSJEk1YPEmSZIkSTVg8SZJkiRJNWDxJkmSJEk1YPEmSZIkSTVg8SZJkiRJNRDj9COAEfEF4FMDvvxc4IsjXB0zq881c/JyzZy83GEyvzMzHzDKlZlkQ7SRfh7NrHNuUzKryjVzPHPXbR/HqngbRkQcycy9Zk5OrpmTl2vm5OVW9V61cX4ezaxzblMyq8o1s365dpuUJEmSpBqweJMkSZKkGpik4u1/mjlxuWZOXq6Zk5db1XvVxvl5NLPOuU3JrCrXzJrlTsw1b5IkSZI0ySbpzJskSZIkTSyLN0mSJEmqgdoXbxHx2oi4MyKOlph5QUS0I+JjEXFLRDyvhMx7R8RfRMSHO5lXFp3Zlb0lIj4UEe8sMfO2iPhoRNwcEUdKyjwnIt4WER+PiKWI+P6C876n8/5Wprsi4peLzOzk/tvOZ+hoRCxExL1LyHxeJ++WIt/jWvuDiNgeEddGxF93/p0qIfNfdt7rP0ZEIUMTr5P7is7n9yMR8faIOKeEzP/Uybs5It4bEQ8eZaYG15T2sZNbSRtp+1hopm3k6HMa0UZOevtY++INeD3w+JIzTwLPz8yHAY8Gnh0RDys4827gMZn5COCRwOMj4tEFZ654HrBUUla3VmY+ssTf5XgV8O7M/GfAIyj4PWfmJzrv75HAHuDrwNuLzIyI84DnAnszczewBbi04MzdwLOAi1nerk+KiO8uKO71fOv+4CXAdZn5EOC6zv2iM48CPwn86Yiz+uVeC+zOzIcDfwVcXkLmKzLz4Z3P8TuBl444U4N7Pc1oH6G6NtL2sSC2kYV4Pc1oI9fKnJj2sfbFW2b+KXCs5Mw7MvODndtfZXkndl7BmZmZJzp379mZCh9tJiLOB34ceE3RWVWKiLOBHwbmATLzG5n55RJX4QDwycz8VAlZW4Fvj4itwH2A/1dw3jTwgcz8emaeBP6E5Z32yK2zP7gEeEPn9huAnyg6MzOXMvMTo8zZYO57O9sY4Ebg/BIy7+q6exYl7Je0MU1pHztZpbeRto+lso0cgaa0kZPePta+eKtaRFwIXAR8oISsLRFxM3AncG1mFp4J/CbwIuAfS8jqlsB7I+KmiLishLydwBeA13W6wLwmIs4qIXfFpcBC0SGZ+VngvwKfBu4AvpKZ7y049ijwQxFx/4i4D/BE4IKCM7vtyMw7Orc/B+woMbtKvwBcU0ZQRMxFxO3A0/DMmzrKbB87eWW3kb+J7WNZbCOL08Q2stbto8XbECJiG/AHwC+vqq4LkZmnOqdezwcu7pxqL0xEPAm4MzNvKjJnHfsy81HAE1judvPDBedtBR4F/E5mXgR8jdF3HVhTRHwb8GTgrSVkTbF8lG0n8GDgrIj42SIzM3MJ+HXgvcC7gZuBU0Vm9liXpAFnhiJiluXua28uIy8zZzPzgk7ec8rI1Hgru32EcttI28dy2kewjSxTE9rISWgfLd4GFBH3ZLlhenNm/mGZ2Z3uCm2Kv5bhB4EnR8RtwFXAYyLiTQVnAqePfpGZd7Lcx/3igiM/A3ym60jt21hurMrwBOCDmfn5ErIeC/xtZn4hM/8B+EPgB4oOzcz5zNyTmT8MHGe5v3lZPh8RDwLo/Htnidmli4hnAE8Cnpbl/5Dnm4GfKjlTY6bK9hFKayNtH8tjG1msxrSRk9I+WrwNICKC5b7fS5n5GyVlPmBlZJyI+HbgR4GPF5mZmZdn5vmZeSHLXRauz8xCj0ABRMRZEXHfldvAj7HcraAwmfk54PaI+J7OrAPAx4rM7DJDCd1BOj4NPDoi7tP5HB+ghAvPI+KBnX//Cct9+Q8XndnlauDpndtPB95RYnapIuLxLHfjenJmfr2kzId03b2EgvdLGm9VtI+d3FLbSNvH0tpHsI0sWiPayIlqHzOz1hPLf9B3AP/A8tGhgyVk7mP5tPJHWD69fTPwxIIzHw58qJN5FHhpydt5P/DOkrK+C/hwZ7oFmC0p95HAkc42/iNgqoTMs4AvAWeX+H95ZWcHchT438C9Ssj8M5Yb+w8DBwrM+Zb9AXB/lkfQ+mvgfcD2EjKf0rl9N/B54D0lvddbgdu79ku/W0LmH3Q+Sx8B/g9wXtGfJ6fB/79KyCy9fezkVtZG2j4WmmsbOdqcRrSRk94+RidQkiRJkjTG7DYpSZIkSTVg8SZJkiRJNWDxJkmSJEk1YPEmSZIkSTVg8SZJkiRJNWDxJkmSJEk1YPEmSZIkSTXw/wEPAfcRgOwOMQAAAABJRU5ErkJggg==\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "naf_mfcc_median = np.array([np.median(mfcc(naf[1], naf[0], nfft=1024), axis=0) for naf in naf_audios])# ...\n",
    "nam_mfcc_median = np.array([np.median(mfcc(nam[1], nam[0], nfft=1024), axis=0) for nam in nam_audios])# ...\n",
    "\n",
    "\n",
    "f, (ax1, ax2) = pl.subplots(1,2, sharey='all', figsize=(15,4))\n",
    "ax1.plot()\n",
    "ax1.boxplot(naf_mfcc_median)\n",
    "ax1.set_title('Natural Female')\n",
    "ax1.grid()\n",
    "ax2.boxplot(nam_mfcc_median)\n",
    "ax2.set_title('Natural Male')\n",
    "ax2.grid()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On a trouvé que les paires de MFCC (8,9), (8,4), (9,4) pourraient être utiles pour la prédiction. Mais pour cette expérience, on peut simplement utiliser l'ensemble complet des MFCC."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MLP"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exploring the number of epochs and hyper parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import mlp_backprop_momentum as mlp\n",
    "import k_fold_cross_validation as cv\n",
    "\n",
    "mfccs = np.concatenate((\n",
    "    nam_mfcc_median,\n",
    "    naf_mfcc_median\n",
    "))\n",
    "\n",
    "# We use -1 and 1 for classes because we use the tanh function\n",
    "classes = np.concatenate(\n",
    "    (\n",
    "        np.repeat(-1, len(nam_mfcc_median)),\n",
    "        np.repeat(1, len(naf_mfcc_median))\n",
    "    )\n",
    ")\n",
    "# Using pandas for format\n",
    "df_mfcc = pd.DataFrame(data=mfccs)\n",
    "\n",
    "df_mfcc['class'] = classes.tolist()\n",
    "# Hyper parameters...\n",
    "N_INITS = 10\n",
    "EPOCHS = 200\n",
    "N_NEURONS = [2, 4, 8, 16, 32]\n",
    "LEARNING_RATE = 0.001\n",
    "MOMENTUM = 0.5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MSE = np.zeros((len(N_NEURONS), N_INITS, EPOCHS))\n",
    "\n",
    "for i_h, h in enumerate(N_NEURONS):                                     # looping over the number of hidden neurons\n",
    "    print('Testing', h, 'neurons...')\n",
    "    nn = mlp.MLP([13,h,1], 'tanh')\n",
    "    for i in np.arange(N_INITS):                                        # looping over the initializations\n",
    "        nn.init_weights()\n",
    "\n",
    "        MSE[i_h, i, :] = nn.fit((df_mfcc.loc[:, df_mfcc.columns != 'class'], df_mfcc['class']),\n",
    "                                learning_rate=LEARNING_RATE,\n",
    "                                momentum=MOMENTUM,\n",
    "                                epochs=EPOCHS)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pl.figure(figsize=(15,4))\n",
    "p_count = 0\n",
    "for n in np.arange(MSE.shape[0]):\n",
    "    pl.subplot(1, MSE.shape[0], n+1)\n",
    "    for i in np.arange(MSE.shape[1]):\n",
    "        pl.plot(MSE[n,i,:], c='b')\n",
    "    pl.ylim(0,1)\n",
    "    pl.xlabel('Epochs')\n",
    "    pl.ylabel('MSE')\n",
    "    pl.title(str(N_NEURONS[n]) + ' neurons')\n",
    "    pl.grid()\n",
    "pl.tight_layout()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On peut voir que l'erreur ne diminue pas de manière significative après ~100 Epochs.\n",
    "Un learning rate de 0.001 et un momentum de 0.5 donne des résultats qui semblent acceptables\n",
    "\n",
    "## Exploring the number of hidden neurons\n",
    "Knowing that there are no significant improvements after 50 iterations, we can now further explore how the complexity of the model (number of hidden neurons) is linked to the generalization performance (test error). The following snippet allows you to explore both the number of epochs and the number of hidden neurons without restarting the training.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "EPOCHS = 150\n",
    "K = 5\n",
    "N_TESTS = 10\n",
    "N_NEURONS = [2, 4, 6, 8, 10, 15, 20, 25, 30]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MSE_train = np.zeros((len(N_NEURONS), EPOCHS, N_TESTS))\n",
    "MSE_test = np.zeros((len(N_NEURONS), EPOCHS, N_TESTS))\n",
    "\n",
    "for i_h, h in enumerate(N_NEURONS):                                     # looping the number of hidden neurons\n",
    "    print('Testing', h, 'neurons...')\n",
    "    nn = mlp.MLP([13,h,1], 'tanh')\n",
    "    for i in np.arange(N_TESTS):                                        # looping the tests\n",
    "        nn.init_weights()                                               # the network has to be reinitialized before each test\n",
    "        temp1, temp2 = cv.k_fold_cross_validation_per_epoch(nn,         # notice that we do not use cv.k_fold_cross_validation\n",
    "                                                            df_mfcc.to_numpy(),    # but cv.k_fold_cross_validation_per_epoch which\n",
    "                                                            k=K,        # returns a value of error per each epoch\n",
    "                                                            learning_rate=LEARNING_RATE,\n",
    "                                                            momentum=MOMENTUM,\n",
    "                                                            epochs=EPOCHS)\n",
    "        # temp1 and temp2 are the training and test error. One value per epoch\n",
    "        MSE_train[i_h, :, i] = temp1\n",
    "        MSE_test[i_h, :, i] = temp2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MSE_train_mean = np.mean(MSE_train, axis=2)\n",
    "MSE_test_mean = np.mean(MSE_test, axis=2)\n",
    "MSE_train_sd = np.std(MSE_train, axis=2)\n",
    "MSE_test_sd = np.std(MSE_test, axis=2)\n",
    "\n",
    "v_min = min(np.min(MSE_train_mean), np.min(MSE_test_mean))\n",
    "v_max = max(np.max(MSE_train_mean), np.max(MSE_test_mean))\n",
    "\n",
    "n_rows = int(np.ceil(len(N_NEURONS)/3.0))\n",
    "pl.figure(figsize=(12,3*n_rows))\n",
    "for i_n, n in enumerate(N_NEURONS):\n",
    "    pl.subplot(n_rows, min(3, len(N_NEURONS)), i_n+1)\n",
    "    pl.fill_between(np.arange(EPOCHS), MSE_train_mean[i_n,:], MSE_train_mean[i_n,:]+MSE_train_sd[i_n,:], facecolor='blue', alpha=0.5, label='Train')\n",
    "    pl.fill_between(np.arange(EPOCHS), MSE_train_mean[i_n,:], MSE_train_mean[i_n,:]-MSE_train_sd[i_n,:], facecolor='blue', alpha=0.5)\n",
    "    pl.fill_between(np.arange(EPOCHS), MSE_test_mean[i_n,:], MSE_test_mean[i_n,:]+MSE_test_sd[i_n,:], facecolor='red', alpha=0.5, label='Test')\n",
    "    pl.fill_between(np.arange(EPOCHS), MSE_test_mean[i_n,:], MSE_test_mean[i_n,:]-MSE_test_sd[i_n,:], facecolor='red', alpha=0.5)\n",
    "    pl.ylim(0.95*v_min,0.5*v_max)\n",
    "    pl.ylabel('MSE')\n",
    "    pl.xlabel('Number of epochs')\n",
    "    pl.title(str(K)+'-fold CV with '+str(n)+' hidden neurons')\n",
    "    pl.legend()\n",
    "    pl.grid()\n",
    "pl.tight_layout()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pl.figure(figsize=(15,8))\n",
    "pl.subplot(2,1,1)\n",
    "pl.imshow(MSE_train_mean, vmin=np.min(MSE_train_mean), vmax=np.percentile(MSE_train_mean, 90), aspect=3, interpolation='nearest')\n",
    "pl.yticks(np.arange(len(N_NEURONS)), N_NEURONS)\n",
    "pl.xlabel('Epochs')\n",
    "pl.ylabel('Number of hidden Neurons')\n",
    "pl.title('Training')\n",
    "pl.colorbar()\n",
    "pl.subplot(2,1,2)\n",
    "pl.imshow(MSE_test_mean, vmin=np.min(MSE_test_mean), vmax=np.percentile(MSE_test_mean, 90), aspect=3, interpolation='nearest')\n",
    "pl.yticks(np.arange(len(N_NEURONS)), N_NEURONS)\n",
    "pl.xlabel('Epochs')\n",
    "pl.ylabel('Number of hidden Neurons')\n",
    "pl.title('Test')\n",
    "pl.colorbar()\n",
    "pl.tight_layout()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Avec ces représentations nous pouvons voir qu'un nombre de neurones dans la couche cachée supérieur à 15 réduit les performances de notre modèle sur le set de test. A priori, cela signifie qu'il perd en capacité de généralisation.\n",
    "\n",
    "## Final model\n",
    "\n",
    "Notre modèle final aura donc 15 neurones, 0.001 de learning rate, un momentum de 0.5 et 80 epochs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "nn = mlp.MLP([13,15,1], 'tanh')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def k_fold_cross_validation_without_matrix(mlp, dataset, k=5, learning_rate=0.01, momentum=0.7, epochs=100, threshold=None):\n",
    "    MSE_train_mean = 0.0\n",
    "    MSE_test_mean = 0.0\n",
    "\n",
    "    parts = cv.split_dataset(dataset, k)\n",
    "    target_test = []\n",
    "    output_test = []\n",
    "\n",
    "    for k_i in np.arange(k):\n",
    "        mlp.init_weights()\n",
    "\n",
    "        training_parts = set(np.arange(k))\n",
    "        training_parts.remove(k_i)\n",
    "        dataset_train = np.concatenate([parts[i] for i in list(training_parts)])\n",
    "        dataset_test = parts[k_i]\n",
    "\n",
    "        input_data = dataset_train[:,0:mlp.n_inputs]\n",
    "        output_data = dataset_train[:,mlp.n_inputs:(mlp.n_inputs+mlp.n_outputs)]\n",
    "        input_data_test = dataset_test[:,0:mlp.n_inputs]\n",
    "        output_data_test = dataset_test[:,mlp.n_inputs:(mlp.n_inputs+mlp.n_outputs)]\n",
    "\n",
    "        mlp.fit((input_data, output_data),\n",
    "                learning_rate=learning_rate, momentum=momentum, epochs=epochs)\n",
    "        MSE_train, _ = mlp.compute_MSE((input_data, output_data))\n",
    "        MSE_train_mean += MSE_train\n",
    "\n",
    "        MSE_test, temp_out = mlp.compute_MSE((input_data_test, output_data_test))\n",
    "        MSE_test_mean += MSE_test\n",
    "        output_test.append(temp_out)\n",
    "        target_test.append(output_data_test)\n",
    "\n",
    "    target_test = np.concatenate(target_test, axis=0)\n",
    "    output_test = np.concatenate(output_test, axis=0)\n",
    "\n",
    "    if threshold is None:\n",
    "        return (MSE_train_mean / k, MSE_test_mean / k)\n",
    "    else:\n",
    "        return (MSE_train_mean / k, MSE_test_mean / k, target_test, output_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........."
     ]
    }
   ],
   "source": [
    "N_SPLITS = 10\n",
    "\n",
    "MSE_train = np.zeros(N_SPLITS)\n",
    "MSE_test = np.zeros(N_SPLITS)\n",
    "\n",
    "targets = []\n",
    "outputs = []\n",
    "\n",
    "for d in np.arange(N_SPLITS):\n",
    "    sys.stdout.write('.')\n",
    "    temp1, temp2, target, output = k_fold_cross_validation_without_matrix(nn,\n",
    "                                                              df_mfcc.to_numpy(),\n",
    "                                                              k=K,\n",
    "                                                              learning_rate=LEARNING_RATE,\n",
    "                                                              momentum=MOMENTUM,\n",
    "                                                              epochs=80,\n",
    "                                                              threshold=0.0)\n",
    "    MSE_train[d] = temp1\n",
    "    MSE_test[d] = temp2\n",
    "    targets.append(target)\n",
    "    outputs.append(output)\n",
    "\n",
    "targets = np.concatenate(targets, axis=0)\n",
    "outputs = np.concatenate(outputs, axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "conf_mat = cv.compute_confusion_matrix(targets, outputs, 0.0)\n",
    "\n",
    "y_pred = [-1 if y[0] < 0.0 else 1 for y in outputs.tolist()]\n",
    "y_true = [-1 if y[0] < 0.0 else 1 for y in targets.tolist()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "[float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float,\n float]"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE training:  [0.00969101 0.01158236 0.01335902 0.01218801 0.01084943 0.01461603\n",
      " 0.01245587 0.01239983 0.01371381 0.01701425]\n",
      "MSE test:  [0.26195272 0.1971239  0.26632603 0.16265709 0.17243826 0.22001966\n",
      " 0.24405556 0.27585747 0.27208121 0.37380548]\n",
      "Confusion matrix:\n",
      "[[341.  19.]\n",
      " [ 38. 322.]]\n"
     ]
    }
   ],
   "source": [
    "print('MSE training: ', MSE_train)\n",
    "print('MSE test: ', MSE_test)\n",
    "print('Confusion matrix:')\n",
    "print(conf_mat)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Calcul des performances..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9208333333333333\n",
      "F1-Score:  0.9228687415426252\n",
      "Recall 0.9472222222222222\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "# Rows are the actual class and columns are the predicted class\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_true, y_pred))\n",
    "print(\"F1-Score: \", metrics.f1_score(y_true, y_pred))\n",
    "print(\"Recall\", metrics.recall_score(y_true, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}