{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hold-out validation\n",
    "In hold-out validation the dataset is split in two parts: one part is used during training and the other is used for testing the generalization capabilities of the model. This method has the advantage of being easy to implement. However, in hold-out validation the generalisation performance is evaluated with a single test, using a dataset partition that not necessarily represents the whole distribution of the whole dataset. Hence, it can produce some undesirable behaviours that lead to a wrong assessment of the performance of the model. In this notebook you are going to explore the behaviour of hold-out validation by simulating datasets with diverse degrees of complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "import sys\n",
    "from ipywidgets import interact, widgets\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset\n",
    "This function creates a dataset with two classes in two dimensions. It has two parameters: the size of the dataset and the spread of each one of the classes. A high spread value makes both classes to superpose, making the classification more difficult."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(n, s):\n",
    "    n1 = int(np.ceil(n / 2.0))\n",
    "    n2 = int(np.floor(n / 2.0))\n",
    "    x1 = np.random.normal(-1, s, n1)\n",
    "    y1 = np.random.uniform(-1, 1,  n1)\n",
    "    x2 = np.random.normal(1, s, n2)\n",
    "    y2 = np.random.uniform(-1, 1, n2)\n",
    "    return np.stack((np.concatenate((x1, x2)), np.concatenate((y1, y2)), np.concatenate((np.ones(n1), -1*np.ones(n2)))), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dataset(s):\n",
    "    dataset = create_dataset(200, s)\n",
    "    pl.scatter(dataset[:,0], dataset[:,1], c=[(['b', 'r'])[int(cl > 0)] for cl in dataset[:,2]])\n",
    "    pl.xlim(-3,3)\n",
    "    pl.ylim(-1,1)\n",
    "    pl.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffd5a46fc1ca44cbb36b657d015d1825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.1, description='Spread:', max=1.0, min=0.1, step=0.01), Output()), _â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interact(plot_dataset, s=widgets.FloatSlider(value=0.1, min=0.1, max=1.0, step=0.01, description='Spread:',));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlp_backprop_momentum as mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring hold-out validation\n",
    "The following function splits the dataset in two parts. The parameter `train_test_ratio` controls the proportions of the partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, train_test_ratio = 0.8):\n",
    "    index_all = np.arange(dataset.shape[0])\n",
    "    np.random.shuffle(index_all)\n",
    "    break_point = int(train_test_ratio * len(index_all))\n",
    "    index_train = index_all[0:break_point]\n",
    "    index_test = index_all[break_point:]\n",
    "    dataset_train = dataset[index_train,:]\n",
    "    dataset_test = dataset[index_test,:]\n",
    "    return (dataset_train, dataset_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment\n",
    "In this experiment we create datasets with different degrees of complexity and we test the behaviour of hold-out validation with each one of them. For each dataset, we split the dataset several times, which generates different partitions training/testing. We also initializes the neural networks several times with each partition in order to be sure that the results are not a special case of a lucky initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_INITS = 2\n",
    "N_SPLITS = 10\n",
    "DATASET_SIZE = 200\n",
    "EPOCHS = 100\n",
    "N_NEURONS = 2\n",
    "LEARNING_RATE = 0.001\n",
    "MOMENTUM = 0.7\n",
    "TRAIN_TEST_RATIO = 0.8\n",
    "DATA_PARAMS = np.arange(0.4, 0.71, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing dataset with variance: 0.4\n",
      "....................20 tests done\n",
      "Testing dataset with variance: 0.5\n",
      "....................20 tests done\n",
      "Testing dataset with variance: 0.6\n",
      "....................20 tests done\n",
      "Testing dataset with variance: 0.7\n",
      "....................20 tests done\n"
     ]
    }
   ],
   "source": [
    "MSE_train = np.zeros((len(DATA_PARAMS), N_SPLITS * N_INITS, EPOCHS))\n",
    "MSE_test = np.zeros((len(DATA_PARAMS), N_SPLITS * N_INITS, EPOCHS))\n",
    "MSE_test_last = np.zeros((len(DATA_PARAMS), N_SPLITS * N_INITS))\n",
    "for p, s in enumerate(DATA_PARAMS):                                     # looping the set of parameters\n",
    "    print('Testing dataset with variance:', s)\n",
    "\n",
    "    dataset = create_dataset(DATASET_SIZE, s)\n",
    "    \n",
    "    for d in np.arange(N_SPLITS):                                       # looping the splits\n",
    "        dataset_train, dataset_test = split_dataset(dataset, TRAIN_TEST_RATIO)\n",
    "    \n",
    "        for i in np.arange(N_INITS):                                    # looping the initializations\n",
    "            sys.stdout.write('.')\n",
    "            nn = mlp.MLP([2,N_NEURONS,1], 'tanh')\n",
    "            input_data = dataset_train[:,0:nn.n_inputs]\n",
    "            output_data = dataset_train[:,nn.n_inputs:(nn.n_inputs+nn.n_outputs)]\n",
    "            input_data_test = dataset_test[:,0:nn.n_inputs]\n",
    "            output_data_test = dataset_test[:,nn.n_inputs:(nn.n_inputs+nn.n_outputs)]\n",
    "\n",
    "            t = (d * N_INITS) + i\n",
    "            MSE_train[p,t,:], MSE_test[p,t,:] = nn.fit((input_data, output_data), \n",
    "                                                       (input_data_test, output_data_test),\n",
    "                                                       learning_rate=LEARNING_RATE, momentum=MOMENTUM, epochs=EPOCHS)\n",
    "            MSE_test_last[p,t] = MSE_test[p,t,-1]\n",
    "    print(N_INITS * N_SPLITS, 'tests done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the resulting MSE, we can observe that each partition, i.e., each run of hold-out validation, generates different values of model error. For the same dataset, running hold-out validation several times does not generate coherent assessments of model error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of rows must be a positive integer, not 1.0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\NELSON~1\\AppData\\Local\\Temp/ipykernel_920/726869227.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn_rows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMSE_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mpl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_rows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMAX_COL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMSE_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mpl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMSE_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Training'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36msubplot\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1267\u001b[0m     \u001b[1;31m# First, search for an existing subplot with a matching spec.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1268\u001b[1;33m     \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSubplotSpec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_from_subplot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0max\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\gridspec.py\u001b[0m in \u001b[0;36m_from_subplot_args\u001b[1;34m(figure, args)\u001b[0m\n\u001b[0;32m    595\u001b[0m                             f\"{len(args)} were given\")\n\u001b[0;32m    596\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 597\u001b[1;33m         \u001b[0mgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSpec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_gridspec_exists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    598\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m             \u001b[0mgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSpec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigure\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\gridspec.py\u001b[0m in \u001b[0;36m_check_gridspec_exists\u001b[1;34m(figure, nrows, ncols)\u001b[0m\n\u001b[0;32m    223\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mgs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m         \u001b[1;31m# else gridspec not found:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mGridSpec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mncols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigure\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\gridspec.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, nrows, ncols, figure, left, bottom, right, top, wspace, hspace, width_ratios, height_ratios)\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfigure\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m         super().__init__(nrows, ncols,\n\u001b[0m\u001b[0;32m    386\u001b[0m                          \u001b[0mwidth_ratios\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwidth_ratios\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m                          height_ratios=height_ratios)\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\gridspec.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, nrows, ncols, height_ratios, width_ratios)\u001b[0m\n\u001b[0;32m     47\u001b[0m         \"\"\"\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIntegral\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mnrows\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m     50\u001b[0m                 f\"Number of rows must be a positive integer, not {nrows!r}\")\n\u001b[0;32m     51\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mncols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIntegral\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mncols\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Number of rows must be a positive integer, not 1.0"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_COL = 4\n",
    "n_rows = np.ceil(float(MSE_train.shape[0]) / MAX_COL)\n",
    "pl.figure(figsize=(12, 4 * n_rows))\n",
    "for d in range(MSE_train.shape[0]):\n",
    "    pl.subplot(n_rows, MAX_COL, d+1)\n",
    "    for r in range(MSE_train.shape[1]):\n",
    "        pl.plot(MSE_train[d,r,:], c='c', label='Training')\n",
    "        pl.plot(MSE_test[d,r,:], c='r', label='Testing')\n",
    "        if d == 0 and r == 0:\n",
    "            pl.legend()\n",
    "    pl.ylim(0, 0.6)\n",
    "    pl.ylabel('MSE')\n",
    "    pl.xlabel('Iteration')\n",
    "    pl.title('Spread: '+str(DATA_PARAMS[d]))\n",
    "    pl.grid()\n",
    "pl.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that the red curves end (last iteration) at different values of MSE. Different partitions are more or less easy to learn. Some data partitions are memorized by the neural networ: which means a low training error and a high testing error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.boxplot(MSE_test_last.T, positions=DATA_PARAMS, widths=0.05)\n",
    "for c in np.arange(MSE_test_last.shape[1]):\n",
    "    pl.scatter(DATA_PARAMS, MSE_test_last[:,c], s=10, c='g', marker='x')\n",
    "\n",
    "pl.xlim(np.min(DATA_PARAMS)-0.1, np.max(DATA_PARAMS)+0.1)\n",
    "pl.xlabel('Spread')\n",
    "pl.ylabel('MSE')\n",
    "pl.title('Several runs of hold-out validation')\n",
    "pl.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "widgets": {
   "state": {
    "be367bcade124b30aeaf8724d3ffbbe4": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
